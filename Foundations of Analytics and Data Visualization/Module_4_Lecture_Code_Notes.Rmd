# Module 4 Lecture Notes

#####################################################
#### Section #1 - Intro (Discrete Distributions) #### 
#####################################################

# Numeric variables are either discrete or continuous. The outcomes of a continuous numeric variable come from a measuring process while those of a discrete variable come from a counting process. In this lecture, the probability distributions of discrete variables are explored. A probability distribution for a discrete random variable is defined in terms of a list of all possible numerical outcomes along with the probability of each outcome. The list of all outcomes is known as the support of the random variable. The probability distribution is specified in terms of a function, the probability mass function that maps each outcome to its probability.

###################################################
#### Random Variable Example - Number of Heads #### 
###################################################

# Let the random variable X be the number of heads observed when a fair coin is tossed three times. The support for X is SX = {0, 1, 2, 3}. For computing the probabilities, examine the sample space for the experiment:

# S = {HHH, HHT, HTH, HTT, THH, THT, TTH, TTT}

# Out of the eight outcomes, only one outcome (TTT) has the number of heads 0; three outcomes (HTT, THT, TTH) have the number of heads 1; three outcomes (HHT, HTH, THH) have the number of heads 2; and one outcome (HHH) has the number of heads 3.

# The problems on (PAGE 3) can be modeled in R as follows. The support set for the random variable and the probabilities for this distribution are:

(x <- c(0, 1, 2, 3))

(f <- c(1/8, 3/8, 3/8, 1/8))

# The mean of the distribution is:

(mu <-sum(x * f))

# The variance of the distribution is:

(sigmaSquare <- sum((x - mu)^2 * f))

# The standard deviation of the distribution is:

(sigma <- sqrt(sigmaSquare))

# The cumulative distribution for the random variable is:

(F <- cumsum(f))

###################################################
#### Random Variable Example - Age of Students #### 
###################################################

# Suppose the ages of ten students enrolled in a class are 21, 25, 27, 23, 21, 21, 25, 25, 21, and 27. Let the random variable X be the age of a randomly selected student in the class. The frequency distribution of X is shown in the table on (PAGE 5):

(ages <- c(21, 25, 27, 23, 21, 21, 25, 25, 21, 27))

(ctable <- table(ages))

# The above contingency table is converted to a data frame as follows:

(dframe <- as.data.frame(ctable))

# The inputs for the random variable X are the distinct ages:

(x <- as.numeric(as.character(dframe$ages)))

# Similarly, the probability distribution for the random variable is:

(f <- dframe$Freq / (sum(dframe$Freq)))

#######################################
#### Discrete Uniform Distribution #### 
#######################################

# A discrete uniform distribution is a symmetric probability distribution where a finite number of input values are equally likely. Consider the rolling of a single die. The outcomes 1, 2, ... , 6 are equally likely, each occurring with a probability of 1/6. If a discrete random variable X has m input values 1, 2, ... , m, then X has the discrete uniform distribution when P(X = x) = 1/m , for all values of x from 1 to m.

# The values can be explicitly computed in R as follows: (The input sequence is 1..6 and each of the 6 probabilities are 1/6.)

(x <- 1:6)

(f <- rep(1/6, 6))

# The mean value is calculated as follows:

(mu <- sum(x*f))

# The variance is computed using the following formula

(sigmaSquare <- sum((x - mu)^2 * f))

# The cumulative distribution function of the above discrete uniform random variable is calculated as follows:

x/6

# Sometimes, the input values for the discrete uniform random variable are in the integer range [a, b], inclusive where a < b. In this case, the probability mass function is (SEE PAGE 9)

# The rolling die example can be modeled in R as follows. The probability, P(X = 1), is:

(m <- 6)
dunif(1, max = m)

# The PMF can be generated as shown below.

(pmf <- dunif(1:m, max = m))

# A plot of the PMF for the uniform distribution using the following code is shown below.

plot(1:m, pmf, type='h', xlab='x', ylab='PMF', ylim = c(0, 0.2))
abline(h=0)

# The CDF for the above distribution is:

(cdf <- punif(1:m, max = m))

# The CDF can also be calculated using the PMF as follows:

cumsum(pmf)

# The qunif function is the quantile function that is the inverse of the punif function, i.e., it returns the value for which the CDF is given.
options(digits=2)
qunif(0.4, max = 6)

# The data for a discrete uniform random variable can be generated in R using the sample function with the replace option set to TRUE. The following code generates the data for a fair die rolled twenty times:

sample(6, size = 20, replace=T)

# The following code generates five random numbers in the given range from 10 to 20:

sample(10:20, size = 5, replace = T)

# The following code generates ten outcomes from flipping a fair coin:

sample(c("H", "T"), size = 10, replace = T)

##########################################
#### Binomial Distribution Background #### 
##########################################

# The binomial distribution is based on binomial coefficients and Bernoulli trials. A Bernoulli trial is a random experiment with only two possible outcomes, success and failure.

##########################
#### Bernoulli Trials #### 
##########################

# A Bernoulli trial is a random experiment in which there are only two possible outcomes—success (S) and failure (F). The random variable X in a Bernoulli trial is defined as follows:

# X = 1, if the outcome is a success (S), and X = 0, if the outcome is a failure (F). 

# Let the probability of success be p. Then the probability of failure is (1– p).

# Using R, the sample() function can be used to draw the samples with the specified distribution. The first argument is the list of outcomes 0, 1. Since the first outcome in this list is the negative outcome, its probability is 1– p. The following examples (PAGE 13) show ten random samples with p = 1 and p = 3 , respectively:

p <- 1/4
sample(0:1, size = 10, replace = T, prob = c(1-p,p))

p <- 3/4
sample(0:1, size = 10, replace = T, prob = c(1-p,p))

############################################
#### Section #2 - Binomial Distribution #### 
############################################

# The binomial distribution is the probability distribution for the number of successes in a sequence of Bernoulli trials. The number of outcomes that contain x successes out of n Bernoulli trails is the binomial coefficient (n). A binomial x random variable X counts the number of successes in n Bernoulli trials. The distribution of X is described by the two parameters, n (the number of trials) and p (the success probability).

# Notation

# X ~ binom(size = n, prob = p)

############################################
#### Bernoulli Trials—Coin Toss Example #### 
############################################

# A coin is tossed three times. Let success be the outcome of getting a head for each toss. Given that the coin is unfair and has an 80% chance of landing on heads, the probability of success, p, is 0.8. The probability of failure is 0.2. For each toss, let s denote the success outcome and f denote the failure outcome. The possible outcomes for three tosses and their corresponding probabilities are shown in the table on (PAGE 14):

#########################################
#### Example Using R—Tossing 5 Coins #### 
#########################################

# The coin-tossing example can be modeled using R as follows. Suppose a fair coin is tossed five times. The random variable X is the number of heads, and success probability is 1/2.

# The probability that, say, X = 3, can directly be calculated using the binomial formula as shown below.
options(digits=4)

n <- 5
p <- 1/2

choose(n,3) * p^3 * (1-p)^2

# The stats package provides the dbinom function to compute the probability for the given value of X . The probability for X = 3 can be calculated as follows.

dbinom(3, size = n, prob = p)

# The probability mass function for a sequence (or list) of values can be directly calculated as shown below. The following arguments for the function calculate all probabilities for 0..n.

dbinom(0:n, size = n, prob = p)

# Similarly, the probabilities for X = 1 and X = 5 can be calculated by providing the list of values as the first argument.

dbinom(c(1,5), size = n, prob = p)

# The probability for three or fewer heads, P(X <| 3), can be calculated as the sum of the probabilities P(X = 0) + P(X = 1) + P(X = 2) + P(X = 3). The cumulative probability is shown below.

sum(dbinom(0:3, size = n, prob = p))

# The pbinom function provides the alternative to directly compute the cumulative probability. P(X % 3) is also calculated as shown below.

pbinom(3, size = n, prob = p)

# The probability of 4 or more heads can be calculated as P(X = 4) + P(X = 5) as shown below.

sum(dbinom(4:n, size = n, prob = p))

# The above probability is the same as 1 $ P(X % 3). Using the pbinom function, the value is:

1 - pbinom(3, size = n, prob = p)

# Instead of using the complement, the value P(X |> 4), or P(X > 3), can be calculated by providing the additional argument lower.tail = FALSE in the formula for computing P(X <| 3) as shown below. This adds the values of the probabilities from the next integer of the first argument to the size of the experiment.

pbinom(3, size = n, prob = p, lower.tail = F)

# A spike plot of the probability distribution for the binomial random variable can be produced as shown below. The probabilities, computed as heights, correspond to the input values 0..n. The plot is generated for the sequence using the vertical lines (type = "h"). The tops of the lines are shown as points with the plotting character of a filled circle.

heights <- dbinom(0:n, size = n, prob = p)
plot(0:n, heights, type = "h", main = "Spike splot of X", xlab = "x", ylab = "PMF")
points(0:n, heights, pch = 16)

########################
### Plotting the CDF ###
########################

# The cumulative distribution function of the binomial random variable can be plotted in R by using the cumsum and stepfun functions. Given the probabilities, the cumsum function returns the cumulative probabilities. The first value of 0 (corresponding to FX (x), x < 0) is inserted into the cdf variable.
# Thestepfun, for the given values of (x1,x2,...,xn) and (y0,y1,y2,...,yn), returns piecewise constant functions. The values returned by this function are constant for [x0 , xi+1 ). The following example shows how a stepfun works:

x <- c(0,1,2,3)
y <- c(0,10,20,30,40)

stepfun(x,y)

# For the coin-tossing examples, the CDF is plotted as shown below. The step function values are plotted using the plot function. The verticals option is FALSE so that vertical lines are not drawn at the steps.

n <- 5
p <- 1/2

pmf <- dbinom(0:n, size = n, prob = p)
cdf <- c(0, cumsum(pmf))
cdfplot <- stepfun(0:n, cdf)
plot(cdfplot, verticals = F, pch = 16, main = "Step plot", xlab = "x", ylab = "CDF")

# The qbinom function is the quantile function that is the inverse of the pbinom function, i.e., it returns the value for which the CDF is given.

qbinom(0.8125, size = n, prob = p)

# The rbinom function can be used to generate random numbers according to the binomial distribution.

rbinom(10, size = n, prob = p)

# A plot of the frequency distribution of a sample of 1000 numbers following the binomial distribution can be generated as shown below.

y <- rbinom(1000, size = n, prob = p)
table(y)
plot(table(y), type = "h", col="red")

###################################
### Hypergeometric Distribution ###
###################################

# In the binomial distribution, the Bernoulli trials are independent of each other and hence the probability of success remains the same for each trial. Also, the sample data is selected with replacement. In the hypergeometric distribution, the sample data is selected without replacement. Hence, the outcomes are dependent on the previous observations. See (PAGE 31) for all examples.

# Notation
# X ~ hyper(m = M, n = N, k = K)

# The associated R functions for the PMF and CDF of the hypergeometric distribution are dhyper(x, m, n, k) and phyper(x, m, n, k), respectively. The above problem with five white balls, three black balls, and a sample size of two is modeled as follows:

M <- 5
N <- 3
K <- 2

(pmf <- dhyper(0:K, m = M, n = N, k = K))

# The corresponding cumulative probabilities are shown below.

(cdf <- phyper(0:K, m = M, n = N, k = K))

# The quantile function, qhyper, is the inverse of the phyper function, returning the number for the specified CDF.

qhyper(0.64, m = M, n = N, k = K)

rhyper(10, m = M, n = N, k = K)

######################################
### Example Using R - Faulty Chips ###
######################################

# Suppose there are 20 faulty chips out of manufactured lot of 1000 chips. For quality control, 50 chips are selected at random without replacement. The random variable is the number of faulty chips in the selected sample. In this hypergeometric distribution, M = 20, N = 980, and K = 50.

# The probability of exactly 2 faulty chips in the sample using R:

M <- 20
N <- 980
K <- 50

dhyper(2, m = M, n = N, k = K)

sum(dhyper(0:2, m = M, n = N, k = K))

phyper(2, m = M, n = N, k = K)

# To calculate P(X |>) 3) = P(X > 2), the lower.tail property of the phyper function is used. This is equivalent to 1 $ P(<| 2)

phyper(2, m = M, n = N, k = K, lower.tail = F)

# The probability distribution for the number of faulty chips can be calculated and plotted as follows:

(pmf <- dhyper(0:K, m = M, n = N, k = K))
plot(0:K, pmf, typer = "h", xlab = "x", ylab = "PMF", ylim = c(0, 0.5))
abline(h=0)

#############################################
#### Section #3 - Geometric Distribution #### 
#############################################

# The geometric distribution concerns the number of failures before a success occurs in a sequence of Bernoulli trials. In a geometric distribution, the random variable X is the number of failures before a success

# Notation - X ~ geom(prob = p)

# The associated R functions for the PMF and CDF of the geometric distribution are dgeom(x, prob) and pgeom(x, prob), respectively. Consider the coin-tossing example with a fair coin where the probability of success (say, getting a head) is 1.

# THe probabilities from table on (PAGE 36) are computed in R as follows
options(digits = 3)
p <- 1/2
dgeom(2, prob = p)

# Similarly, the PMF can be calculated in R as follows:

(pmf <- dgeom(0:10, prob = p))

# The plot of the above distribution is shown below.

plot(0:10, pmf, type = "h", xlab = "x", ylab = "PMF")
abline(h=0)

#####################################################
#### Section #3 - Negative Binomial Distribution #### 
#####################################################

# The negative binomial distribution concerns the number of failures until a total of r successes occur in a sequence of Bernoulli trials. In a negative binomial distribution, the random variable X is the number of failures that precede the rth success.

# Notation: X ~ nbinom(size = r, prob = p)

# The associated R functions for the PMF and CDF of the negative binomial distribution are dnbinom(x, size, prob) and pnbinom(x, size, prob), respectively.

r <- 3
p <- 1/2

dnbinom(5, size = r, prob = p)

# The probability mass function of the negative binomial variable is calculated in R as follows:

(pmf <- dnbinom(0:10, size = r, prob = p))

# The plot of the above distribution is shown below.

plot(0:10, pmf, type = "h", xlab = "x", ylab = "PMF", ylim = c(0, 0.2))
abline(h=0)

# The probability that at most 5 failures are observed is:
#          P(X %5)=P(X =0)+p(X =1+...+P(X =5))
# The cumulative probability can be computed in R as follows:

pnbinom(5, size = r, prob = p)

# The plot for the cumulative distribution function is shown below.

(cdf <- c(0, cumsum(pmf)))

cdfplot <- stepfun(0:10, cdf)
plot(cdfplot, pch = 16, main = "", xlab = "x", ylab = "CDF")

###########################################
#### Section #4 - Poisson Distribution #### 
###########################################

# The Poisson distribution is used to model the frequency with which a specified event occurs during a particular period of time. Some examples where the Poisson distribution is applicable are:

# The number of patients arriving in an ER between 11 PM and midnight
# The number of customers arriving in a bank between 9 AM and 11 AM
# The number of support calls received per day

# The Poisson distribution is identified by a single parameter, A (lambda), which is the mean or the average number of events per time unit [0, 1].

# Notation: X ~ pois(lambda = A)

# The associated R functions for the PMF and CDF of the Poisson distribution are dpois(x, lambda) and ppois(x, lambda), respectively.

# P(X=6)=e$886 =0.122

# The above probability can be computed in R using the dpois function as follows:

dpois(6, lambda = 8)

# Chances are 12.2% that exactly 6 patients will arrive during this period.

# The probability that at most 2 patients arrive during this interval is:

ppois(2, lambda = 8)

# Chances are only 1.37% that 2 or fewer patients will arrive during this interval.

# The probability of between 5 and 10 patients (inclusive) arriving is:

diff(ppois(c(4, 10), lambda = 8))

# The probability mass function of the random variable X can be computed as follows:

(pmf <- dpois(0:20, lambda = 8))

# The above values can be plotted showing the distribution for the first 20 values.

plot(0:20, pmf, type = "h", xlab = "x", ylab = "PMF", ylim = c(0, 0.15))
abline(h=0)

# The above figure shows that the Poisson distribution is right-skewed (all Poisson distributions are right-skewed).

# Suppose that a fast food drive-thru serves, on average, 3 vehicles per 5-minute interval during lunchtime. In this case, if X is number of vehicles arriving in a 5-minute period, then X + pois(lambda = 3). If the lunch hour is Noon to 1 PM, the total time period is 60 minutes (twelve 5-minute units). If Y is the number of vehicles arriving during the lunch hour, then Y + pois(lambda = 3 # 12 = 36).

###############################################
#### Section #5 - Continuous Distributions #### 
###############################################

# For continuous random variables, the probability density function (PDF) defines the distribution of values. Common distributions include the normal distribution (also known as Gaussian distribution), uniform distribution (also known as rectangular distribution), and exponential distribution.

# The normal distribution is symmetric and has a bell shape. Most of the values tend to cluster around the mean. Since this is symmetrical distribution, the mean equals the median. In the uniform distribution, each value has an equal probability of occurrence. The uniform distribution is also symmetrical, hence the mean equals the median. The exponential distribution is skewed to the right, hence its mean is larger than the median. The density curve is always on or above the x-axis, and the total area under a density curve equals 1.

#########################################
#### Continuous Uniform Distribution #### 
#########################################

# For the random variable X with the continuous uniform distribution over the interval [a, b], the probability of occurrence is the same anywhere in the range.

# Notation: X ~ unif(min = a, max = b)

# Using R, the associated functions for the PDF and CDF are dunif(x, min = a, max = b) and punif(x, min = a, max = b), respectively.

########################################
#### Example 1—Uniform Distribution #### 
########################################

# A common use of the uniform distribution is in the selection of random numbers. For random sampling, the uniform distribution [0, 1] is used.

# The probability of getting a random number between 0.2 and 0.4, P[0.2 < X < 0.4] can be calculated in R as follows.

punif(0.4, min = 0, max = 1) - punif(0.2, min = 0, max = 1)

########################################
#### Example 2—Uniform Distribution #### 
########################################

# Suppose that the download time of songs follows a uniform distribution between 2.5 and 6.5 seconds. The probability that the download time will be more than 5 seconds can be calculated as follows:

1 - punif(5, min = 2.5, max = 6.5)

# or

punif(5, min = 2.5, max = 6.5, lower.tail = F)

#########################################
#### Section #6: Normal Distribution #### 
#########################################

# The normal distribution is the most common continuous distribution in practice. The classic bell-shaped curve represents the normal distribution. The probability is calculated for values that occur within a certain range or interval as the area under the curve. A normal distribution is completely determined by the mean (!) and the standard deviation (" ). Two normally distributed random variables having the same mean and standard deviation must have identical distributions.

# A normal distribution is symmetric and centered around its mean, while the spread of the curve depends on the standard deviation. As the standard deviation increases, the distribution will be flatter and more spread out. The following figure shows three normal distributions with standard deviations of 0.5, 1, and 2, respectively, all centered around the mean equal to 0.

# In a normal distribution, almost all the possible observations of the random variable lie within three standard deviations of either side of the mean. The curve associated with the normal distribution satisfies the following properties:

# The curve is bell shaped
# The curve is centered around the mean (u)
# The curve is close to the x-axis for values below u - 3o and for values above u + 3o

# Notation: X ~ norm(mean = u, sd = o)

# The associated PDF and CDF functions in R are dnorm(x, mean = 0, sd = 1) and pnorm(x, mean = 0, sd = 1), respectively.

#######################################
#### Example - Normal Distribution #### 
#######################################

# The gestation period for humans is normally distributed with a mean of 266 days and a standard deviation of 16 days. The normal curve for this distribution can be plotted in R as follows:

(x <- seq(200, 320))

(pdf <- dnorm(x, mean = 266, sd = 16))

plot(x, pdf, type = "l", col = "red", xlim = c(200, 320), ylim = c(0, 0.03), xaxt = "n", yaxt = "n", main = "Gestation Period", xlab = "Days", ylab = "PDF")
axis(side = 1, at = c(218, 234, 250, 266, 282, 298, 314), labels = T)
axis(side = 2, at = c(0, 0.01, 0.02, 0.03), labels = T)

# The cumulative probability of a baby being born within the mean value of 266 days is:

mu <- 266
sigma <- 16

pnorm(mu, mean = mu, sd = sigma)

# The above value shows that 50% of babies are born within the mean value.

# The cumulative probability of a baby being born within less than the 3rd standard deviation, u - 3o, (218 days) is:

pnorm(mu - 3*sigma, mean = mu, sd = sigma)

# The above value shows that 0.135% of babies are born with a gestation of 218 or fewer days.
# The cumulative probability of a baby being born within 3 standard deviations from the mean, (u - 3o , u + 3o ), (218 days to 314 days) is:

pnorm(mu + 3*sigma, mean = mu, sd = sigma) - pnorm(mu - 3*sigma, mean = mu, sd = sigma)

# The above value shows that 99.73% of babies are born within a gestation period of 218 days to 314 days.
# The cumulative probability of a baby being born within 2 standard deviations from the mean, (u - 2o , u + 2o ), ( 234 days to 298 days) is:

pnorm(mu + 2*sigma, mean = mu, sd = sigma) - pnorm(mu - 2*sigma, mean = mu, sd = sigma)

# The above value shows that 95.45% of babies are born within a gestation period of 234 days to 298 days. Similarly, the cumulative probability of a baby being born within 1 standard deviation from the mean, (u - o, u + o), (250 days to 282 days) is:

pnorm(mu + sigma, mean = mu, sd = sigma) - pnorm(mu - sigma, mean = mu, sd = sigma)

# The above value shows that 68.27% of babies are born within a gestation period of 250 days to 282 days. 

# The CDF for the gestation period is plotted in R as follows:

x <- seq(212, 320)

cdf <- pnorm(x, mean = 266, sd = 16)

plot(x, cdf, type = "l", col = "red", xlim = c(212, 320), ylim = c(0, 1), xaxt = "n", main = "Gestation Period CDF", xlab = "Days", ylab = "CDF")
abline(h=0)
axis(side = 1, at = c(218, 234, 250, 266, 282, 298, 314), labels = T)

######################################
#### Standard Normal Distribution #### 
######################################

# Given a normally distributed random variable X with mean u and standard deviation o , the standardized normal random variable Z, is derived as follows:

# Notation: Z ~ noram(mean = 0, sd = 1)

# The standard normal curve satisfies the following properties:
# The total area under the standard normal curve is 1
# The curve extends indefinitely in both directions along the x-axis
# The curve is symmetric around x = 0
# Almost all of the area under the standard curve lies between $3 and 3 68.27% of the observations lie within one standard deviation of the mean (-1, 1) 95.45% of the observations lie within two standard deviations of the mean (-2, 2) 99.73% of the observations lie within three standard deviations of the mean (-3, 3)

# The proportions of the observations falling within the three ranges around the mean can be calculated in R as follows:

100*(pnorm(c(1, 2, 3)) - pnorm(c(-1, -2, -3)))

##########################
#### Normal Quantiles #### 
##########################

# Given a number, the cumulative distribution function, pnorm, computes the probability that a normal random variable will be less than that number. The quantile function, qnorm(x, mean=0, sd=1), does the reverse. Given the probability, the function returns the number whose cumulative distribution matches the probability. For a standard normal variable with mean 0 and standard deviation 1, the qnorm function takes the probability and returns the associated z-score.

qnorm(0.5, mean = 0, sd = 1)

# Example:

# Suppose the scores on a test follow the normal distribution with a mean value of 80 and a standard deviation of 5. The minimum score for a student to be in the top 5% can be calculated as follows. P(X < 0.95) is the area under the normal curve representing the bottom 95% of the class. The maximum value of X that satisfies the condition can be computed as shown below

qnorm(0.95, mean = 80, sd = 5)

# If the scores are rounded, a student should have 88 or above to be in the top 5% of the class. Similarly, to be in the top 1% of the class, the following function gives the minimum score as 92.

qnorm(0.99, mean = 80, sd = 5)

############################################################
#### Generating Random Numbers with Normal Distribution #### 
############################################################

# The rnorm function, rnorm(n, mean = 0, sd = 1), generates n random numbers that follow the normal distribution with the corresponding mean and standard deviation.

# The random values for 20 students can be generated with a mean value of 80 and standard deviation of 5 as follows:

(y <- rnorm(20, mean = 80, sd = 5))

# The generated values, for say, 1000 numbers, can be rounded and plotted as shown below.

y <- rnorm(1000, mean = 80, sd = 5)
y <- round(y)
table(y)
plot(table(y), type = "h")

##############################################
#### Section #7: Exponential Distribution #### 
##############################################

# The exponential distribution is a continuous distribution and ranges from zero to positive infinity. This distribution is commonly used in queuing theory for waiting time distributions, the length of time between arrivals, patients entering a hospital, etc.

# Notation: X ~ exp(rate = A)

# The associated PDF and CDF functions in R are dexp(x, rate = 1) and pexp(x, rate = 1), respectively.

##########################################
#### Example—Exponential Distribution #### 
##########################################

# Suppose customers come to a bank at the rate of 20 per hour (A = 20). If a customer has just arrived, the probability that the next customer will arrive within 1 minute is calculated as follows. Since the arrival rate is per hour, 1 minute corresponds to 1/60 of the hour. Hence the required probability is:

pexp(1/60, rate = 20)

# The probability that a customer will arrive within the next minute is 28.3%.

# The PDF for this distribution can be plotted in R as follows:

x <- seq(0, 1, by = 1/60)
pdf <- dexp(x, rate = 20)

plot(x, pdf, type = "l", col = "red", xlim = c(0,0.4))
abline(h=0)

cdf <- pexp(x, rate = 20)
plot(x, cdf, type = "l", col = "red", xlim = c(0, 0.4))

######################################
#### Section #8: Random Variables #### 
######################################

# A random variable is a function that associates a number with each outcome. So, the outcome selected is a quantitative variable whose value depends on chance. The following are some examples of random variables:

# The sum of the dice when a pair of dice is rolled.
# The number of heads when a coin is tossed, say, three times The number of siblings for the students in a class, etc.

# The discrete random variables can be modeled in R as follows. Given a particular sample probability space, the addrv function adds the specified random variables to the probability space. In the following example, the standard die is rolled twice and the outcomes of the two rolls make up the probability space. The first two and last two out of the 36 outcomes are also shown.

(S <- rolldie(2, makespace = T))
head(S, n = 2)
tail(S, n = 2)

# Let the random variable U be the sum of the two faces of the coin. The random variable defined using the expression X1 + X2 is added to the data using the addrv function as follows:

(S <- addrv(S, U = X1 + X2))

# Portions of the data frame with the values of the random variable are shown below.

head(S, n = 2)

S[10:16, ]

tail(S, n = 2)

# Given the data frame with the computed random variable, U , the sum of the two rolls of the die, the following can easily be determined. The probability that the sum of the two rolls is at most 6 or greater than 6 is answered as shown below. (Note that the two probabilities add to 1, as they are complementary.)

Prob(S, U <= 6)

Prob(S, U > 6)

###################################
#### Multiple Random Variables #### 
###################################

# The random variable can also be defined using the function (FUN) argument to the addrv function. By default, the specified function applies to the non-probability columns of the data frame. Since multiple random values are being modeled using the same data, the applicable columns for the random variable need to be specified explicitly. This is done through the invars argument for the addrv function. The previous example is modified further by adding the random variables V (maximum of the two rolls X1 and X2) and W (minimum of the two rolls X1 and X2).

S <- addrv(S, FUN = max, invars = c("X1", "X2"), name = "V")

S <- addrv(S, FUN = max, invars = c("X1", "X2"), name = "W")

# Portions of the data frame with the values of the random variables are shown below.

head(S, n = 2)

S[10:16, ]

tail(S, n = 2)




#########################
### Formulas for Quiz ###
#########################

# Suppose you go to bed at 10 PM and wake up at 6 AM and check your email the first thing after waking up. On an average, your inbox receives 105 emails during that period. What is the probability that you will have in between 97 and 109 emails (both inclusive) to read? (round the answer to three decimals)

diff(ppois(c(127, 138), lambda=130))

# Suppose you go to bed at 10 PM and wake up at 6 AM and check your email the first thing after waking up. On an average, your inbox receives 110 emails during that period. What is the probability that you will have at most 107 emails to read? (round the answer to three decimals)

ppois(73, lambda=70)


# Suppose you go to bed at 10 PM and wake up at 6 AM and check your email the first thing after waking up. On an average, your inbox receives 70 emails during that period. What is the probability that you will have exactly 70 emails to read? (round the answer to three decimals)
 
dpois(85, lambda=85)

# Suppose the scores of an exam follow a normal distribution with mean = 65 and standard deviation = 6. What is the chance that a randomly selected student will score at least 75? (round up the answer to nearest integer)

pnorm(61, mean = 65, sd=6)

# Suppose the scores of an exam follow a normal distribution with mean = 55 and standard deviation = 6. What is the chance that a randomly selected student will score in between 46 and 65? (round up the answer to nearest integer)

pnorm(55:72, mean = 65, sd=5)


# Suppose the scores of an exam follow a normal distribution with mean = 70 and standard deviation = 6. What is the minimum score that a randomly selected student should get to be in the top 5%? (round up the answer to nearest integer)

qnorm(0.99, mean = 60, sd=9)



# Suppose a discrete random variable has a uniform distribution from 1 to 50. The probability that the random variable is at least 28 is

punif(23, max=50, lower.tail = F)

# Suppose the scores of an exam are all integer scores and follow a discrete uniform distribution from 50 to 80. The probability that a randomly selected student will score 76 is
dunif(64, min = 60, max = 70)


sum(dbinom(0:3, size=5, prob=0.24))

# At the carnival, you decided to play the balloon and dart game to pop the balloons with the darts. You are provided 5 darts. Your chance of popping a balloon with a dart is 24%. What is the probability that you will pop at least 3 balloons with the 5 darts (round the answer to three decimals)?
pbinom(3, size=5, prob=0.63, lower.tail = F) 

# At the carnival, you decided to play the balloon and dart game to pop the balloons with the darts. You are provided 5 darts. Your chance of popping a balloon with a dart is 77%. What is the probability that you will pop atmost 4 balloons with the 5 darts (round the answer to three decimals)?
pbinom(0:4, size=5, prob=0.54, lower.tail = T) 


# At the carnival, you decided to play the balloon and dart game to pop the balloons with the darts. You are provided 5 darts. Your chance of popping a balloon with a dart is 80%. What is the probability that you will pop exactly 2 balloons with the 5 darts (round the answer to three decimals)?
dbinom(4, size = 5, prob = 0.30)

# In a game of chutes and ladders, suppose you need a 3 to win the game. You are rolling a 6-faced fair die. What is the probability that you will win the game on the eighth try? (round the answer to four decimals)

set.seed(10)
library(purrr)
count = 0
for(i in 1:10000)
{
j = 1
x = rdunif(1, 6, 1)
while(x != 5)
{
j = j+1
x = rdunif(1, 6, 1)
}
if(j == 8)
{
count = count + 1
}
}
count/10000

# In a game of chutes and ladders, suppose you need a 6 to win the game. You are rolling a 6-faced fair die. What is the probability that you will win the game in at most 6 tries? (round the answer to four decimals)

set.seed(10)
library(purrr)
count = 0
for(i in 1:10000)
{
j = 1
x = rdunif(1, 5, 1)
while(x != 4)
{
j = j+1
x = rdunif(1, 5, 1)
}
if(j <= 3)
{
count = count + 1
}
}
count/10000

# A fair coin (Heads/Tails) is tossed 16 times. What is the probability that you will get extactly 7 Heads? (round the answer to four decimals)

n <- 17

p <- 1/2

dbinom(7, size = n, prob = p)

# A fair coin (Heads/Tails) is tossed 6 times. What is the probability that you will get at least 2 Heads? (round the answer to four decimals)

n <- 9

p <- 1/2

pbinom(6, size = n, prob = p, lower.tail = F)

# An M&M candy dispenser has 25 red, 25 blue, and 25 green M&Ms. The dispenser dispenses 20 M&Ms each time. What is the probability, that on the first use, you will get at most 3 red M&Ms out of the 20 dispensed. (round the answer to three decimals)

M <- 20
N <- 40
K <- 20

sum(dhyper(0:10, m = M, n = N, k = K))

# An M&M candy dispenser has 30 red, 30 blue, and 30 green M&Ms. The dispenser dispenses 20 M&Ms each time. What is the probability, that on the first use, you will get 9 blue M&Ms out of the 20 dispensed. (round the answer to three decimals)

M <- 35
N <- 70
K <- 20
sum(dhyper(6, m = M, n = N, k = K))

# Consider a slot machine with 3 wheels (reels). Each reel has 10 slots, 0, 1, ..., 9. Suppose you have a win if the 3 slots match (0-0-0, 1-1-1, ..., 9-9-9). You decided to play until you win 3 times. What is the probability that you will walk out after exactly 355 tries? (round the answer to four decimals)

p <- 0.008450704225

dnbinom(360, size = 3, prob = p)

# Consider a slot machine with 3 wheels (reels). Each reel has 10 slots, 0, 1, ..., 9. Suppose you have a win if the 3 slots match (0-0-0, 1-1-1, ..., 9-9-9). You decided to play until you win 3 times. What is the probability that you will walk out after at most 315 tries? (round the answer to four decimals)


p <- 0.009523809524

pnbinom(160, size = 3, prob = p)

# Consider a slot machine with 3 wheels (reels). Each reel has 10 slots, 0, 1, ..., 9. Suppose you have a win if the 3 slots match (0-0-0, 1-1-1, ..., 9-9-9). You decided to play until you win 3 times. The machine says that your chances of matching the 3 slots is 59%. What is the minimum number of tries you will need to win 3 times?

p <- 0.01966666667

qnbinom(0.59, size = 3, prob = p) * 2

########################
### CODE FOR PROJECT ###
########################


```{r, echo = FALSE}
wins <- ufc_data[c("B_wins", "R_wins", "B_losses", "R_losses")]

p <- plot_ly(ufc_data, x = ~wins , type="box", name = 'Red/Blue: Wins vs. Losses', colors = c("blue", "red"))
  add_trace(p, x = ~B_wins, name = 'Blue Wins', color = "Blue") |>
  add_trace(p, x = ~R_wins, name = 'Red Wins', color = "Red") |>
  add_trace(p, x = ~B_losses, name = 'Blue Losses', color = "Blue") |>
  add_trace(p, x = ~R_losses, name = 'Red Losses', color = "Red") |>
  layout(xaxis = x)
colSums(wins)
```




















