# CS544 Module 3 Assignment
## Student: David J Lotito

###############
### Part 1) ###
###############

# Initialize the dataset about prime numbers as shown below:

df <- read.csv("https://people.bu.edu/kalathur/datasets/myPrimes.csv")
head(df, n=100)

# The resulting data frame of the primes below 10000 along with their last and first digits is as shown below:

# a) Show the barplot of the frequencies for the last digit.

(lastdigit <- df[ , "LastDigit"])
table(lastdigit)

barplot(table(lastdigit), xlab = "Number", ylab = "Frequency", col = "blue", ylim = c(0,400))

# b) Show the barplot of the frequencies for the first digit.

(firstdigit <- df[ , "FirstDigit"])
table(firstdigit)

barplot(table(firstdigit), xlab = "Number", ylab = "Frequency", col = "yellow", ylim = c(0,200))

# c) What inferences do you draw from these two plots? (two inferences from each plot)

# In a) the distributions are largely the same showing that a lot of the values fall within the same range 1,3,7,9 and not in 2, 5. This plot also tells us that the frequency of the last digits for prime numbers are almost all odd numbers.

# In b) The plot shows that there is a lot more frequency in 1s vs. the rest of the values, this leads me to believe that as the prime numbers increase so will the 1s indicating that this number will always be the leader. The 3 & 4 values are identical leading me to belive that as the numbers increase these two values continue to rise at the same pace, but the even numbers in the graph show a steady decline from 2, 4, 6, 8 the values are steadily decreasing.

###############
### Part 2) ###
###############

# Initialize the dataset about the quarter coin productions of the 50 US states by the DenverMint and PhillyMint. The numbers in the dataset (in thousands ) are the number of quarters minted. With the R code for the following:

us_quarters <- read.csv("https://people.bu.edu/kalathur/datasets/us_quarters.csv")
head(us_quarters)

# a) For which state were the highest number of quarters produced by each mint? For which state were the lowest number of quarters produced by each mint?

(denvermint <- us_quarters[c("State","DenverMint")])

(phillymint <- us_quarters[c("State","PhillyMint")])


denvermint[which.max(denvermint$DenverMint),]
# For the Denver Mint, Connecticut had the highest number of quarters produced at 657880

phillymint[which.max(phillymint$PhillyMint),]
# For the Philly Mint, Virginia had the highest number of quarters produced at 943000

denvermint[which.min(denvermint$DenverMint),]
# For the Denver Mint, Oklahoma had the lowest number of quarters produced at 194600

phillymint[which.min(phillymint$PhillyMint),]
# For the Philly Mint, Iowa had the lowest number of quarters produced at 213800

# b) What is the value of the total coins in dollars?

(denvermint <- us_quarters[c("DenverMint")])
(phillymint <- us_quarters[c("PhillyMint")])

(sum <- sum(denvermint, phillymint))
(sum <- paste0('$',formatC(sum, big.mark=',', format = 'f', digits = 0)))
# The sum is $34,797,600, almost 35 Million!
sum

# c) Produce the following barplot from the data using the R barplot function with the data for the two mints as a matrix. Write any two striking inferences you can observe by looking at the plot.

(rownames(us_quarters) <- us_quarters$State)
(us_quarters <- as.matrix(us_quarters[c('DenverMint', 'PhillyMint')]))


options(scipen=5)
barplot(t(us_quarters), beside = TRUE, legend.text = TRUE, ylim=c(0,1000000), xlim=c(0,150), col=c("blue", "gray"), las = 2, cex.names=.6)

# Inference #1: The northeast states have a much higher output of coins vs. the rest of the country
# Inference #2: The Denver Mint, on average, is slightly higher than the Philly Mint. For example, looking from Illionis forward you can observe that in most states, Denver is the same or slighlty higher than Philly

# d) Show the scatter plot of the number of coins between the two mints. Write any two inferences you can observe looking at the plot.

us_quarters <- read.csv("https://people.bu.edu/kalathur/datasets/us_quarters.csv")

(scatter <- us_quarters[c("DenverMint", "PhillyMint")])

attach(scatter)

plot(scatter)

# Inference #1: Most of the coins produced at each mint fall between 200000 & 300000
# Inference #2: The data has quite a few outliers in the PhillyMint data

# e) Show the side-by-side box plots for the two mints. Write any two inferences for each of the box plots.

us_quarters <- read.csv("https://people.bu.edu/kalathur/datasets/us_quarters.csv")

(box <- us_quarters[c("DenverMint", "PhillyMint")])

attach(box)

box

boxplot(box[1:2],main = "Mints", col = rainbow(8))

# Inference #1 DeverMint: The box plot shows that the data contains some outliers. These would need to be treated depending on how you move forward with processing the data
# Inference #2 DeverMint: The median (indicated by the black line) shows us where the average of the values fall ~300000

# Inference #1 PhillyMint: The data shows us that the majority of the data falls in a smaller range compared to the DenverMint, with the median also slightly below that of the DenverMint.
# Inference #2 PhillyMint: There is quite a few outliers in the PhillyMint data, we know from the data analysis we did in the prior exercises that the PhillyMint produced the highest number of quarters overall & had the largest value in terms of quarters produced per a state, hence the reason we can see so many outliers.

# f) Using R code, what states would be considered as outliers for each of the two mints. Use the five number summary function to derive the outlier bounds

us_quarters <- read.csv("https://people.bu.edu/kalathur/datasets/us_quarters.csv")
head(us_quarters)

(us_quarters_philly <- us_quarters[c("State","PhillyMint")])
(us_quarters_denver <- us_quarters[c("State","DenverMint")])

# 194600 & 657880 are the outliers based off the fivenum() function
fivenum(us_quarters_denver$DenverMint)

us_quarters_denver[which(us_quarters_denver$DenverMint == 194600), ]
us_quarters_denver[which(us_quarters_denver$DenverMint == 657880), ]
# Oklahoma and Connecticut are the outliers in the Denver Mint

# 213800 & 943000 are the outliers based off the fivenum() function
fivenum(us_quarters_philly$PhillyMint)

us_quarters_philly[which(us_quarters_philly$PhillyMint == 213800), ]
us_quarters_philly[which(us_quarters_philly$PhillyMint == 943000), ]
# Iowa & Virginia are the outliers in the Philly Mint

###############
### Part 3) ###
###############

# Use the stocks dataset with the weekly closing values for the year 2021 initialized as shown below:

stocks <- read.csv("https://people.bu.edu/kalathur/datasets/stocks.csv")
head(stocks)

# a) Show the pair wise plots for all the 6 stocks in the dataset in a single plot.

pairs(stocks[2:7], main = "Stocks", pch=16)

# b) Show the correlation matrix for the 6 stocks in the dataset rounded to 2 decimals.
(cor2 <- cor(stocks[2:7]))
round(cor2, 2)
# c) Provide at least 4 interpretations of the results.

summary(stocks[2:7])

# Interpretation #1: We can see from the matrix that TSLA & AAPL stock prices have a strong positive linear relationship indicating that investors who invest in one more than likely invest in the other.
# Interpretation #2: We can see from the matrix that FB and TSLA stocks are not correlated indicated by the very weak positive relationship
# Interpretation #3: The data tells us that there is a very strong positive relationship between MSFT and GOOG indicating that investors who have an appetite for one stock more than likely have an appetite for the other. 
# Interpretation #4: Finally we can observe from that correlation matrix that TSLA and AMZN have a weak positive correlation. This indicates that an investor in one of these stocks is unlikely to have invested in the other.

# d) Store the correlation matrix from b) in the variable cm. Using loops, for each stock in the dataset, show the top 3 correlated stocks for that respective stock. The code should work for any dataset with any number of stocks. Sample output for the given dataset is shown below:


(cm <- cor(stocks[2:7]))
round(cm, 2)


(list_df <- lapply(1:dim(cm)[2], function(col.number) cm[order(cm[, col.number], decreasing=TRUE)[2:4], col.number, drop = T]))

 
for (c in colnames(cm))
    for (s in list_df)
    if (c != 1)
    print(paste0("Top 3 for Stock ", c, s))
    
    

sort(cm[1:4], decreasing=TRUE)

rev(sort(cm[order(cm[2,2]),]))

t(apply(cm[,], 2, function(x) head(rev(sort(x)), 4)))


(order <- sort(cm, decreasing=TRUE, index.return=TRUE)$x)



###############
### Part 4) ###
###############

# Initialize the scores of 100 students as shown below:

scores <- read.csv("https://people.bu.edu/kalathur/datasets/scores.csv")
head(scores)

# a) Show the default histogram of the student scores. Save the result of the histogram into a variable. Using only the counts and breaks property of this variable, write the R code to produce the following output. The code for the following output should not refer to the individual scores in the dataset.

h <- hist(scores$Score, breaks=8) 

(h2 <- unlist(h[2]))
(h3 <- unlist(h[1]))

(num = length(h2))

for (i in 1:num) {
out <- sprintf("%d students in range (%d,%d]",h2[i],h3[i],h3[i+1])
print(out)
}


# b) Using the breaks option of the histogram, show the histogram and the custom output as shown below so that students in the range (70,90] get an A grade, (50,70] get a B grade, and (30-50] get a C grade. The code for the following output should not refer to the individual scores and should be using only the counts and breaks of the histogram.

h <- hist(scores$Score,breaks=c(30,50,70,90))

h2 <- unlist(h[2])
h3 <- unlist(h[1])
h4 <- c("C","B","A")

num = length(h2)

for (i in 1:num) {
out <- sprintf("%d students in %s grade range (%d,%d]",h2[i],h4[i],h3[i],h3[i+1])
print(out)
}





















